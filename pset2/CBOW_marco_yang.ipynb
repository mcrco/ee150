{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ws2qGWpAFT_n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "import string\n",
        "import re\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oPSR6dPWzkG",
        "outputId": "0a77d92f-f457-4b63-9d52-032d83ba7d79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE9nFOd9vLzs"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Gms5_mtRWJj7"
      },
      "outputs": [],
      "source": [
        "# Fetch and preprocess text\n",
        "def fetch_and_preprocess(url):\n",
        "    response = urllib.request.urlopen(url)\n",
        "    text = response.read().decode('utf-8').lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text.split()\n",
        "\n",
        "# URL for Shakespeare's complete works from Project Gutenberg\n",
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "raw_text = fetch_and_preprocess(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLK5e-g-vNVW"
      },
      "source": [
        "# Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "KEQnmE6XWMNT"
      },
      "outputs": [],
      "source": [
        "# Implement filtering, one-hot encoding, and CBOW dataset construction\n",
        "\n",
        "def fetch_and_preprocess(url):\n",
        "    response = urllib.request.urlopen(url)\n",
        "    text = response.read().decode(\"utf-8\").lower()\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def get_vocab(text, min_word_count):\n",
        "    wcount = defaultdict(int)\n",
        "    for word in text:\n",
        "        wcount[word] += 1\n",
        "    filtered_words = [\n",
        "        word for word, count in wcount.items() if count >= min_word_count\n",
        "        ]\n",
        "    return list(set(filtered_words))\n",
        "\n",
        "\n",
        "class OneHotEncoder():\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = list(vocab)\n",
        "        self.oh_index = {vocab[i]: i for i in range(len(vocab))}\n",
        "\n",
        "    def encode(self, word):\n",
        "        one_hot = torch.zeros(len(self.vocab))\n",
        "        one_hot[self.oh_index[word]] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def decode(self, one_hot):\n",
        "        return self.vocab[torch.argmax(one_hot)]\n",
        "\n",
        "    def __call__(self, word):\n",
        "        return self.encode(word)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShakespeareDataset:\n",
        "    def __init__(self, text, encoder, context_size):\n",
        "        self.text = text\n",
        "        self.encoder = encoder\n",
        "        self.context_size = context_size\n",
        "        self.data = []\n",
        "        for i in tqdm(range(context_size, len(text) - context_size)):\n",
        "            skip = False\n",
        "\n",
        "            target = text[i]\n",
        "            if target not in encoder.oh_index:\n",
        "                skip = True\n",
        "                continue\n",
        "\n",
        "            left = [text[i - j] for j in range(1, context_size + 1)]\n",
        "            right = [text[i + j] for j in range(1, context_size + 1)]\n",
        "            context = left + right\n",
        "            for word in context:\n",
        "                if word not in encoder.oh_index:\n",
        "                    skip = True\n",
        "                    break\n",
        "            if skip:\n",
        "                continue\n",
        "\n",
        "            self.data.append((context, target))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        context, target = self.data[idx]\n",
        "        one_hots = torch.stack([self.encoder(word) for word in context])\n",
        "        return torch.sum(one_hots, dim=0), self.encoder.oh_index[target]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "tiMEGSg1D4uf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GKKjo0LKr9jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f209d2f7-cda2-4799-f85c-3642d105f798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 963379/963379 [00:01<00:00, 611575.96it/s]\n"
          ]
        }
      ],
      "source": [
        "min_word_count = 5\n",
        "CONTEXT_SIZE = 2\n",
        "batch_size = 512\n",
        "\n",
        "encoder = OneHotEncoder(get_vocab(raw_text, min_word_count))\n",
        "train_data = ShakespeareDataset(raw_text, encoder, CONTEXT_SIZE)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True, num_workers=(8 if torch.cuda.is_available() else 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyuNPyOnvUUn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "d69ANHXeWSrk"
      },
      "outputs": [],
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size, encoder):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embedding_dim\n",
        "        self.context_size = context_size\n",
        "        self.encoder = encoder\n",
        "        self.embed = nn.Linear(vocab_size, embedding_dim, bias=False)\n",
        "        self.fc = nn.Linear(embedding_dim, vocab_size, bias=False)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.softmax(self.fc(self.embed(x) / (2 * self.context_size)))\n",
        "\n",
        "    def get_embedding(self, word):\n",
        "        return self.embed(self.encoder(word))\n",
        "\n",
        "    def find_similar(self, word, k):\n",
        "        scores = self.get_embedding(word) @ self.W.T\n",
        "        sorted_idx = [(i, scores[i]) for i in torch.argsort(scores, descending=True)]\n",
        "        best = [self.encoder.decode(sorted_idx[i]) for i in range(k)]\n",
        "        return best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYunj5kVvuKK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "LlFo4HggWp7w"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 512\n",
        "lr = 5e-3\n",
        "weight_decay = 0\n",
        "torch.manual_seed(42)\n",
        "\n",
        "cbow = CBOW(len(encoder.vocab), EMBEDDING_DIM, CONTEXT_SIZE, encoder).to(device)\n",
        "optimizer = optim.Adam(cbow.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "cx_jHS6GZS4M"
      },
      "outputs": [],
      "source": [
        "def plot_loss(batch_losses, batch_indices):\n",
        "\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(20, 10))\n",
        "\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    axs[0].plot(batch_indices, batch_losses)\n",
        "    axs[0].set_xlabel('Batch Index')\n",
        "    axs[0].set_ylabel('Loss')\n",
        "    axs[0].set_title('Loss vs. Batch Index')\n",
        "\n",
        "    axs[1].loglog(batch_indices, batch_losses)\n",
        "    axs[1].set_xlabel('Batch Index')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_title('Loss vs. Batch Index (log log)')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2S04SEkXE58",
        "outputId": "8d81bf29-74ce-45d4-b286-0f8310efe80b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: Can't get attribute 'ShakespeareDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_DIM = 512\n",
        "lr = 5e-3\n",
        "weight_decay = 0\n",
        "\n",
        "cbow = CBOW(len(encoder.vocab), EMBEDDING_DIM, CONTEXT_SIZE, encoder).to(device)\n",
        "optimizer = optim.Adam(cbow.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "num_epochs = 50\n",
        "batch_losses = []\n",
        "batch_indicies = []\n",
        "for epoch in range(num_epochs):\n",
        "    cbow.train()\n",
        "    tot_loss = 0\n",
        "    for batch_idx, (context, target) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        context = context.to(device)\n",
        "        output = cbow(context)\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target)\n",
        "        batch_indicies.append(len(batch_indicies))\n",
        "        batch_losses.append(loss.item())\n",
        "        tot_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\n",
        "        f\"epoch {epoch} average loss for batch of {batch_size}: {tot_loss / len(train_dataloader)}\"\n",
        "    )\n",
        "\n",
        "plot_loss(batch_losses, batch_indicies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72mO5gYjz1oN"
      },
      "source": [
        "# Semantically Similar Clusters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.vocab"
      ],
      "metadata": {
        "id": "fwSvmpRjCP6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_centers = [\n",
        "    \"my\",\n",
        "    \"admirable\",\n",
        "    \"strongly\",\n",
        "    \"enjoyed\",\n",
        "    \"people\",\n",
        "    \"senator\",\n",
        "    \"deceitful\",\n",
        "    \"whore\",\n",
        "    \"and\",\n",
        "    \"prevail\",\n",
        "]\n",
        "\n",
        "for word in word_centers:\n",
        "    cluster = cbow.find_similar(word, 10)\n",
        "    print(cluster)\n"
      ],
      "metadata": {
        "id": "c8g_F90_CLu0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}